{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated File Management and Data Export System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved file: csv_files\\file1.csv\n",
      "Moved file: csv_files\\file2.csv\n",
      "Moved file: csv_files\\file3.csv\n",
      "Moved file: csv_files\\file4.csv\n",
      "Data exported to output.csv in CSV format.\n",
      "Data exported to output.json in JSON format.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure backup folder exists\n",
    "os.makedirs(\"backup_folder\", exist_ok=True)\n",
    "\n",
    "# Move all CSV files to a backup folder\n",
    "csv_files = glob.glob(\"csv_files/*.csv\")\n",
    "\n",
    "for file in csv_files:\n",
    "    shutil.move(file, \"backup_folder/\")\n",
    "    print(f\"Moved file: {file}\")\n",
    "\n",
    "# Automating Export\n",
    "def export_data(df, filename, format):\n",
    "    if format == \"csv\":\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Data exported to {filename} in CSV format.\")\n",
    "    elif format == \"json\":\n",
    "        df.to_json(filename, orient=\"records\")\n",
    "        print(f\"Data exported to {filename} in JSON format.\")\n",
    "    else:\n",
    "        print(\"Unsupported format.\")\n",
    "\n",
    "# Example usage: Creating a sample DataFrame\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'Age': [25, 30, 35],\n",
    "        'City': ['New York', 'Los Angeles', 'Chicago']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Exporting to CSV\n",
    "export_data(df, \"output.csv\", \"csv\")\n",
    "\n",
    "# Exporting to JSON\n",
    "export_data(df, \"output.json\", \"json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-Time Stock Market Data Collection and Analysis Using Python and SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored data for GOOGL\n",
      "Stored data for GOOGL\n",
      "Stored data for GOOGL\n",
      "Stored data for GOOGL\n",
      "Stored data for GOOGL\n",
      "   id symbol            timestamp        open        high         low  \\\n",
      "0   5  GOOGL  2025-02-23 18:58:18  179.634995  179.710007  179.479996   \n",
      "1   4  GOOGL  2025-02-23 18:57:18  179.634995  179.710007  179.479996   \n",
      "2   3  GOOGL  2025-02-23 18:56:17  179.634995  179.710007  179.479996   \n",
      "3   2  GOOGL  2025-02-23 18:55:14  179.634995  179.710007  179.479996   \n",
      "4   1  GOOGL  2025-02-23 18:54:14  179.634995  179.710007  179.479996   \n",
      "\n",
      "        close  volume  \n",
      "0  179.660004  652240  \n",
      "1  179.660004  652240  \n",
      "2  179.660004  652240  \n",
      "3  179.660004  652240  \n",
      "4  179.660004  652240  \n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Database setup\n",
    "db_name = \"stocks.db\"\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS stock_data (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                symbol TEXT,\n",
    "                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "                open REAL,\n",
    "                high REAL,\n",
    "                low REAL,\n",
    "                close REAL,\n",
    "                volume INTEGER)''')\n",
    "conn.commit()\n",
    "\n",
    "# Function to fetch stock data\n",
    "def fetch_stock_data(symbol):\n",
    "    try:\n",
    "        stock = yf.Ticker(symbol)\n",
    "        data = stock.history(period=\"1d\", interval=\"1m\")\n",
    "\n",
    "        if data.empty:\n",
    "            print(f\"No data found for {symbol}. Skipping...\")\n",
    "            return None  # Return None if no data is available\n",
    "\n",
    "        latest = data.iloc[-1]  # Get the most recent price data\n",
    "        return {\n",
    "            \"symbol\": symbol,\n",
    "            \"open\": latest[\"Open\"],\n",
    "            \"high\": latest[\"High\"],\n",
    "            \"low\": latest[\"Low\"],\n",
    "            \"close\": latest[\"Close\"],\n",
    "            \"volume\": latest[\"Volume\"]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {symbol}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to store data in SQLite\n",
    "def store_data(symbol):\n",
    "    stock_data = fetch_stock_data(symbol)\n",
    "    if stock_data:  # Only store if data is available\n",
    "        cursor.execute('''INSERT INTO stock_data (symbol, open, high, low, close, volume)  \n",
    "                          VALUES (?, ?, ?, ?, ?, ?)''',\n",
    "                       (stock_data[\"symbol\"], stock_data[\"open\"],\n",
    "                        stock_data[\"high\"], stock_data[\"low\"], \n",
    "                        stock_data[\"close\"], stock_data[\"volume\"]))\n",
    "        conn.commit()\n",
    "        print(f\"Stored data for {symbol}\")\n",
    "\n",
    "# Function to analyze stock data\n",
    "def analyze_stock(symbol):\n",
    "    df = pd.read_sql_query(\"SELECT * FROM stock_data WHERE symbol=? ORDER BY timestamp DESC LIMIT 100\", \n",
    "                           conn, params=(symbol,))\n",
    "    print(df)\n",
    "\n",
    "# Example Usage\n",
    "symbol = \"GOOGL\"  # Google stock symbol\n",
    "for _ in range(5):  # Fetch data 5 times with intervals\n",
    "    store_data(symbol)\n",
    "    time.sleep(60)  # Wait for 1 minute before fetching again\n",
    "\n",
    "analyze_stock(symbol)\n",
    "\n",
    "# Close database connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to quotes.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define website URL\n",
    "URL = \"http://quotes.toscrape.com/\"\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "def get_quotes(url):\n",
    "    response = requests.get(url, headers=HEADERS)  # Fetch the webpage\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")  # Parse the HTML\n",
    "\n",
    "    quotes_data = []  # Store extracted quotes\n",
    "\n",
    "    quotes = soup.find_all(\"div\", class_=\"quote\")  # Find all quote elements\n",
    "\n",
    "    for quote in quotes:\n",
    "        text = quote.find(\"span\", class_=\"text\").text  # Extract quote text\n",
    "        author = quote.find(\"small\", class_=\"author\").text  # Extract author name\n",
    "        tags = [tag.text for tag in quote.find_all(\"a\", class_=\"tag\")]  # Extract all tags\n",
    "\n",
    "        quotes_data.append({\"Quote\": text, \"Author\": author, \"Tags\": \", \".join(tags)})\n",
    "\n",
    "    return quotes_data  # Return extracted quotes\n",
    "\n",
    "# Scrape the quotes\n",
    "quotes_list = get_quotes(URL)\n",
    "\n",
    "# Convert to DataFrame and save to CSV\n",
    "df = pd.DataFrame(quotes_list)\n",
    "df.to_csv(\"quotes.csv\", index=False)\n",
    "print(\"Data saved to quotes.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
